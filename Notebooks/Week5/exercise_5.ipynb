{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LO vs. NLO simulation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will get familiar with leading order (LO) and next-to-leading order (NLO) simulation. As you might know, beyond the tree level things can get messy. The NLO Feynman diagrams (diagrams with one loop) need to be taken into account and for instance the cross section calculation becomes harder. The NLO diagrams influence the experimental results as well. \n",
    "\n",
    "Your task this week is to analyse two datasets. One is a ttbar process (a process that produces a top quark and an anti-top quark) simulated in LO and the other is a ttbar process in NLO. These simulations have been made in the framework of CMS detector by following the circumstances of 2016 data taking. This means that we are looking at proton-proton collisions with $\\sqrt{s}$ = 13 TeV center-of-mass energy. \n",
    "\n",
    "In this exercise we are studying jets. Jets are collimated sprays of hadrons. Since the lifetime of a top quark is very short, it decays into a jet which is then measured. The difference of LO and NLO can be seen for instance in the jet distributions.\n",
    "\n",
    "The data for transverse momenta and pseudorapidities is structured so that each line contains the data for all jets in the same event. We want to read the data so that its a list of lists where each inner list contains all jets in the same event. An example of doing that can be seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pT of the first jet in the first event is 79.74 GeV\n"
     ]
    }
   ],
   "source": [
    "# An example of how to read the pt values into a 2D Python list\n",
    "pts_LO = []\n",
    "\n",
    "with open('tt_LO_pt1.txt', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        event = line.rstrip('\\n').split(',')\n",
    "        event = [float(i) for i in event]\n",
    "        pts_LO.append(event)\n",
    "        \n",
    "print('The pT of the first jet in the first event is', round(pts_LO[0][0], 2), 'GeV') #79.74"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: LO and NLO jet counts\n",
    "\n",
    "The first task is to plot the numbers of jets per event in a histogram and compare the obtained distributions for LO and NLO. Check from **Moodle** which files you should use.\n",
    "\n",
    "NOTE: The simulated NLO events need to be weighted. Each event has a weight assigned to it which can be found in file tt_NLO_weightsX.txt. Read these and use the resulting array as input for the 'weights' argument in plt.hist. Some weights are negative. The negative weights are an artifact of the cross section calculation. There some terms get a negative weight from a fermion loop. Also normalize the histograms since there are different amounts of LO and NLO events.\n",
    "\n",
    "Return the average number of jets per event for both datasets. Does including NLO Feynman diagrams actually make a difference in practice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Plot a histogram of the number of simulated jets for LO and NLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Plotting pT\n",
    "\n",
    "In this part we will take a look at the transverse momenta of individual jets in the LO dataset after doing some cuts. Accept only the jets that have $50 \\textrm{ GeV} < p_T < 150 \\textrm{ GeV}$ and $|\\eta| < 2.1$. Use the same LO files you used in part 1.\n",
    "\n",
    "Plot the transverse momentum for the accepted jets in a histogram. Normalize the pT distribution. Use 40 bins for the histogram. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the jet pT for LO after cuts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Fitting an exponential\n",
    "\n",
    "The data you plotted should look like it could be reasonably modelled by an exponentially decaying function. Let's train curve fitting once more and try to fit an exponential curve $c_1e^{c_2x}$ to the data ($c_1$ and $c_2$ are constants).\n",
    "\n",
    "We have used scipy.curve_fit before, but here we can be smarter than that. The easiest way to do this is to realize that an exponential curve is just a straight line after taking a logarithm. Therefore you can take the natural\n",
    "logarithms of bin heights and fit a straight line $ax+b$ to them using [numpy.polyfit](https://docs.scipy.org/doc/numpy/reference/generated/numpy.polyfit.html) (fitting polynomials is in general quite easy and much less frustrating than arbitrary functions). The exponential curve is then $e^be^{ax}$.\n",
    "\n",
    "Write a function exponential fit which takes as inputs 'heights' and 'bin_edges', the first two return values given by plt.hist. It calculates the histogram centers and then fits a line to log(heights) using np.polyfit. Return the values $a$ and $e^b$ (NOT just b) **in this order**. Return two separate values, not a list. You can return multiple values by separating them with a comma.\n",
    "\n",
    "**Submit** the function via Moodle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Write a function exponential_fit\n",
    "\n",
    "def exponential_fit(heights, bin_edges):\n",
    "    return 0, 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check by plotting that the curve created by your function fits reasonably well to the data. Return the parameters $a$ and $e^b$ for your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
