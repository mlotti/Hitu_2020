{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LO vs. NLO simulation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will get familiar with leading order (LO) and next-to-leading order (NLO) simulation. As you might know, beyond the tree level things can get messy. The NLO Feynman diagrams (diagrams with one loop) need to be taken into account and for instance the cross section calculation becomes harder. The NLO diagrams influence the experimental results as well. \n",
    "\n",
    "Your task this week is to analyse two datasets. One is a ttbar process (a process that produces a top quark and an anti-top quark) simulated in LO and the other is a ttbar process in NLO. These simulations have been made in the framework of the CMS detector by following the circumstances of 2016 data taking. This means that we are looking at proton-proton collisions with $\\sqrt{s}$ = 13 TeV center-of-mass energy. \n",
    "\n",
    "In this exercise we are studying jets. Jets are collimated sprays of hadrons. Since the lifetime of a top quark is very short, it decays into a jet which is then measured. The difference of LO and NLO can be seen for instance in the jet distributions.\n",
    "\n",
    "The data for transverse momenta and pseudorapidities is structured so that each line contains the data for all jets in the same event. We want to read the data so that it's a list of lists where each inner list contains all jets in the same event. An example of doing that can be seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# An example of how to read the pt values into a nested Python list\n",
    "pts_LO = []\n",
    "pts_NLO = []\n",
    "etas_LO = []\n",
    "etas_NLO = []\n",
    "\n",
    "with open('tt_LO_pt2.txt', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        event = line.rstrip('\\n').split(',')\n",
    "        event = [float(i) for i in event]\n",
    "        pts_LO.append(event)\n",
    "                \n",
    "with open('tt_LO_eta2.txt', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        event = line.rstrip('\\n').split(',')\n",
    "        event = [float(i) for i in event]\n",
    "        etas_LO.append(event)\n",
    "        \n",
    "with open('tt_NLO_pt1.txt', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        event = line.rstrip('\\n').split(',')\n",
    "        event = [float(i) for i in event]\n",
    "        pts_NLO.append(event)\n",
    "        \n",
    "with open('tt_NLO_eta1.txt', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        event = line.rstrip('\\n').split(',')\n",
    "        event = [float(i) for i in event]\n",
    "        etas_NLO.append(event)\n",
    "        \n",
    "NLO_weights = pd.read_csv('tt_NLO_weights1.csv')\n",
    "NLO_weights = NLO_weights.Weights\n",
    "            \n",
    "print('The pT of the first jet in the first event is', round(pts_LO[0][0], 2), 'GeV')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - LO and NLO jet counts\n",
    "\n",
    "The first task is to plot the numbers of jets per event in a histogram and compare the obtained distributions for LO and NLO. Check from Moodle exercise **\"Week 5 coding questions\"** which files you should use.\n",
    "\n",
<<<<<<< HEAD
    "NOTE: The simulated NLO events need to be weighted. Each event has a weight assigned to it which can be found in file tt_NLO_weightsX.txt. Read these and use the resulting array as input for the optional 'weights' argument in plt.hist. Some weights are negative. The negative weights are an artifact of the cross section calculation. There some terms get a negative weight from a fermion loop. Also normalize the histograms since there are different amounts of LO and NLO events.\n",
=======
    "**NOTE**: The simulated NLO events need to be weighted. Each event has a weight assigned to it which can be found in file tt_NLO_weightsX.txt. Read these and use the resulting array as input for the 'weights' argument in plt.hist. Some weights are negative. The negative weights are an artifact of the cross section calculation. There some terms get a negative weight from a fermion loop. Also normalize the histograms since there are different amounts of LO and NLO events.\n",
>>>>>>> 872fad0fb93fcd7b99356b6bcf80d45ff3386f04
    "\n",
    "Calculate the average number of jets per event for both datasets. Note that the weighting in NLO needs to also be included in the calculation of the average. You can do that for example by using histogram bin heights. Does including NLO Feynman diagrams actually make a difference in practice?\n",
    "\n",
    "<br>\n",
    "\n",
    "$\\color{red}{\\text{Write the code below}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Plotting pT\n",
    "\n",
    "In this part we will take a look at the transverse momenta of individual jets in the LO dataset after doing some cuts. Accept only the jets that have $50 \\textrm{ GeV} < p_T < 150 \\textrm{ GeV}$ and $|\\eta| < 2.1$. Use the same LO files you used in part 1.\n",
    "\n",
    "Plot the transverse momentum for the accepted jets in a histogram. Normalize the pT distribution. Use 40 bins for the histogram. \n",
    "\n",
    "<br>\n",
    "\n",
    "$\\color{red}{\\text{Write the code below}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the jet pT for LO after cuts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - Fitting an exponential\n",
    "\n",
    "The data you plotted should look like it could be reasonably modelled by an exponentially decaying function. Let's train curve fitting once more and try to fit an exponential curve $c_1e^{c_2x}$ to the data ($c_1$ and $c_2$ are constants).\n",
    "\n",
    "We have used scipy.curve_fit before, but here we can be smarter than that. The easiest way to do this is to realize that an exponential curve is just a straight line after taking a logarithm. Therefore you can take the natural\n",
    "logarithms of bin heights and fit a straight line $ax+b$ to them using [numpy.polyfit](https://docs.scipy.org/doc/numpy/reference/generated/numpy.polyfit.html) (fitting polynomials is in general quite easy and much less frustrating than arbitrary functions). The exponential curve is then $e^be^{ax}$.\n",
    "\n",
<<<<<<< HEAD
    "Write a function exponential_fit which takes as inputs 'heights' and 'bin_edges', the first two return values given by plt.hist. It calculates the bin centers and then fits a line to ln(heights) using np.polyfit. Return the values $a$ and $e^b$ (NOT just b) **in this order**. Return two separate values, not a list. You can return multiple values by separating them with a comma.\n",
=======
    "Write a function **exponential_fit(heights, bin_edges)** which takes the first two return values given by plt.hist as input parameters. The function should calculate the bin centers and then fit a line to log(heights) using np.polyfit. **Return the values $a$ and $e^b$ (NOT just b) in this order**. Note that the function should return two separate values, not a list. You can return multiple values by separating them with a comma.\n",
    "\n",
    "<br>\n",
>>>>>>> 872fad0fb93fcd7b99356b6bcf80d45ff3386f04
    "\n",
    "$\\color{red}{\\text{Write the code below}}$\n",
    "\n",
    "$\\color{red}{\\text{Submit your function definition to exercise \"EXERCISE_NAME_HERE\" on Moodle.}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the function exponential_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check by plotting that the curve created by your function fits reasonably well to the data. What are the parameters $a$ and $e^b$ for your data?\n",
    "\n",
    "<br>\n",
    "\n",
    "$\\color{red}{\\text{Write the code below}}$\n",
    "\n",
    "$\\color{red}{\\text{Answer the questions in exercise \"Week 5 coding questions\" on Moodle}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fit an exponential curve to the data. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
